# Project Title
Got it âœ… â€” based on everything youâ€™ve told me about your **Capstone: Malicious User Detection** project (email-based insider threat detection, ML models, Streamlit dashboard, etc.), hereâ€™s a **ready-to-use `README.md`** for your repo:

---

# ğŸš¨ Malicious User Detection (Capstone Project)

This project detects **insider threats** and **malicious email behavior** using the Enron email dataset.
It combines **machine learning models**, **NLP preprocessing**, and a **Streamlit web app** for interactive anomaly analysis.

---

## ğŸ“Œ Features

* **Email Preprocessing & Feature Engineering**

  * Text cleaning, tokenization
  * TF-IDF vectorization
  * Sentiment polarity extraction
  * Communication pattern features (to/cc/bcc counts, off-hours detection, etc.)
  * Threat keyword tagging

* **Machine Learning Models**

  * Isolation Forest
  * One-Class SVM
  * Autoencoder (Keras)
  * Random Forest (baseline classifier)

* **Anomaly Detection**

  * Assigns anomaly scores to each email
  * Detects unusual communication patterns
  * Flags potential insider threats

* **Interactive Dashboard (Streamlit)**

  * Upload raw email CSV
  * Automatic feature extraction
  * Model-based anomaly predictions
  * Visualization of results and threat indicators

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ data/                # Dataset files (ignored in Git)
â”‚   â””â”€â”€ raw/             # Raw Enron emails
â”‚   â””â”€â”€ processed/       # Preprocessed data
â”‚
â”œâ”€â”€ models/              # Trained ML models (.pkl, .keras, etc.)
â”‚   â””â”€â”€ models_1/        # Traditional ML (Isolation Forest, RF, etc.)
â”‚   â””â”€â”€ models_2/        # Deep learning + hybrids
â”‚
â”œâ”€â”€ notebooks/           # Jupyter notebooks for training & EDA
â”‚
â”œâ”€â”€ src/                 
â”‚   â”œâ”€â”€ app.py           # Streamlit dashboard
â”‚   â”œâ”€â”€ load_models.py   # Utility functions to load models
â”‚   â”œâ”€â”€ train_local.py   # Local training script
â”‚   â””â”€â”€ preprocessing.py # Text cleaning & feature extraction
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .gitattributes       # Git LFS tracking for large files
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repo

```bash
git clone https://github.com/Neha20704/CAPSTONE-Malicious-User-Detection.git
cd CAPSTONE-Malicious-User-Detection
```

### 2ï¸âƒ£ Install dependencies

```bash
python -m venv venv
source venv/bin/activate   # (Linux/Mac)
venv\Scripts\activate      # (Windows)

pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the Streamlit app

```bash
streamlit run src/app.py
```

---

## ğŸ“Š How It Works

1. **Upload raw email CSV** into the app.
2. **Feature extraction** (text cleaning, NLP, sentiment, metadata).
3. **Models run predictions** (Isolation Forest, OCSVM, Autoencoder, etc.).
4. **Results shown on dashboard** with anomaly scores & visualizations.

---

## ğŸ§ª Models Used

* **Isolation Forest** â†’ detects outliers based on communication patterns.
* **One-Class SVM** â†’ identifies deviations from normal behavior.
* **Autoencoder (Keras)** â†’ reconstructs normal email patterns, high error = anomaly.
* **Random Forest** â†’ supervised baseline model.

---

## ğŸ“ˆ Example Output

* âœ… Normal email â†’ low anomaly score
* âš ï¸ Suspicious email â†’ flagged by one or more models
* ğŸš¨ Malicious email â†’ high anomaly score + multiple threat indicators

---

## ğŸ‘©â€ğŸ’» Team
Developed by:
**Naru Meghana PES2UG22CS341**
**Neha Girish PES2UG22CS346**
**Nikitha Thammaiah PES2UG22CS362**
**Shivprakash G PES2UG23CS822**

---

Would you like me to make this README **lightweight for GitHub** (no dataset/model details since youâ€™re ignoring them),
or **full academic style** (with methodology + evaluation results)?
